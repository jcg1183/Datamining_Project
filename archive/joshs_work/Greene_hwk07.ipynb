{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  The following table contains the outcome of classifying 10 testing tuples using a probabliistic classifier.  for each tuple, the actual class (P or N) is given in the second column, and the probability (of class P) returned by the classifier is in the third column.  \n",
    "\n",
    "1 (a) For each row of the table, assume that the threshold of probability for predicting class P is the probability in that row, dtermine the numbers of:  \n",
    "true positives (TP),  \n",
    "false positives (FP),  \n",
    "true negatives (TN),  \n",
    "false negatives (FN),  \n",
    "the true positive rate (TPR) and  \n",
    "false positive rate (FPR)  \n",
    "of the entire set of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class  prob TP FP TN FN  TPR  FPR\n",
      "1      P  0.95  1  0  5  4  0.2  0.0\n",
      "2      N  0.85  1  1  4  4  0.2  0.2\n",
      "3      P  0.78  2  1  4  3  0.4  0.2\n",
      "4      P  0.66  3  1  4  2  0.6  0.2\n",
      "5      N   0.6  3  2  3  2  0.6  0.4\n",
      "6      P  0.55  4  2  3  1  0.8  0.4\n",
      "7      N  0.53  4  3  2  1  0.8  0.6\n",
      "8      N  0.52  4  4  1  1  0.8  0.8\n",
      "9      N  0.51  4  5  0  1  0.8  1.0\n",
      "10     P   0.4  5  5  0  0  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "dict1 = {1: pd.Series([\"P\", .95], index=['class', 'prob']),\n",
    "         2: pd.Series([\"N\", .85], index=['class', 'prob']),\n",
    "         3: pd.Series([\"P\", .78], index=['class', 'prob']),\n",
    "         4: pd.Series([\"P\", .66], index=['class', 'prob']),\n",
    "         5: pd.Series([\"N\", .60], index=['class', 'prob']),\n",
    "         6: pd.Series([\"P\", .55], index=['class', 'prob']),\n",
    "         7: pd.Series([\"N\", .53], index=['class', 'prob']),\n",
    "         8: pd.Series([\"N\", .52], index=['class', 'prob']),\n",
    "         9: pd.Series([\"N\", .51], index=['class', 'prob']),\n",
    "         10: pd.Series([\"P\", .40], index=['class', 'prob']),\n",
    "         }\n",
    "\n",
    "df = pd.DataFrame(dict1).T\n",
    "\n",
    "TP = ['TP']\n",
    "FP = ['FP']\n",
    "TN = ['TN']\n",
    "FN = ['FN']\n",
    "TPR = ['TPR']\n",
    "FPR = ['FPR']\n",
    "\n",
    "df_count = df['class'].value_counts()\n",
    "\n",
    "for i in range(0, len(df.index)+1):\n",
    "    up_slice = df.iloc[0:i+1]\n",
    "         \n",
    "    up_counts = up_slice['class'].value_counts()\n",
    "        \n",
    "    if 'P' in up_counts.index:\n",
    "        TP.append(up_counts['P'])\n",
    "    else:\n",
    "        TP.append(0)\n",
    "        \n",
    "    if 'N' in up_counts.index:\n",
    "        FP.append(up_counts['N'])\n",
    "    else:\n",
    "        FP.append(0)\n",
    "    \n",
    "    down_slice = df.iloc[i+1:]\n",
    "        \n",
    "    down_counts = down_slice['class'].value_counts()\n",
    "        \n",
    "    if 'N' in down_counts.index:\n",
    "        TN.append(down_counts['N'])\n",
    "    else:\n",
    "        TN.append(0)\n",
    "        \n",
    "    if 'P' in down_counts.index:\n",
    "        FN.append(down_counts['P'])\n",
    "    else:\n",
    "        FN.append(0)\n",
    "    \n",
    "    TPR.append(TP[-1] / df_count['P'])\n",
    "    FPR.append(FP[-1] / df_count['N'])\n",
    "    \n",
    "df['TP'] = pd.Series(np.array(TP))\n",
    "df['FP'] = pd.Series(np.array(FP))\n",
    "df['TN'] = pd.Series(np.array(TN))\n",
    "df['FN'] = pd.Series(np.array(FN))\n",
    "df['TPR'] = pd.Series(np.array(TPR))\n",
    "df['FPR'] = pd.Series(np.array(FPR))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (b) Plot the ROC curve for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['TPR']=df['TPR'].astype(float)\n",
    "df['FPR']=df['FPR'].astype(float)\n",
    "\n",
    "plot = df.plot.line(x ='FPR', y='TPR')\n",
    "plot.set_xlabel(\"FPR\")\n",
    "plot.set_ylabel(\"TPR\")\n",
    "plot.set_title(\"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Suppose we have two predictive models, M1 and M2 and run 10 rounds of 10-fold cross-validation test using the two models.  The error rates obtained from the test are given in the following table.\n",
    "\n",
    "2  (a) Training set and testing set are based on the same splits of a 10-fold cross-validation train/test dataset.  Perform a t-test at a significance level of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a significance level of 0.001 and degrees of freedom being 9, the t-score is 4.297.\n",
      "\n",
      "Our t value, 2.471, is less than the t-distribution 4.297, \n",
      "meaning that we must accept the null hypothesis.\n",
      "There is no statistical difference between the models.\n"
     ]
    }
   ],
   "source": [
    "dict2 = {1: pd.Series([30.5, 22.4], index=['m1', 'm2']),\n",
    "         2: pd.Series([32.2, 14.5], index=['m1', 'm2']),\n",
    "         3: pd.Series([20.7, 22.4], index=['m1', 'm2']),\n",
    "         4: pd.Series([20.6, 19.6], index=['m1', 'm2']),\n",
    "         5: pd.Series([31.0, 20.7], index=['m1', 'm2']),\n",
    "         6: pd.Series([41.0, 20.4], index=['m1', 'm2']),\n",
    "         7: pd.Series([27.7, 22.1], index=['m1', 'm2']),\n",
    "         8: pd.Series([26.0, 19.4], index=['m1', 'm2']),\n",
    "         9: pd.Series([21.5, 16.2], index=['m1', 'm2']),\n",
    "         10: pd.Series([26.0, 35.0], index=['m1', 'm2']),\n",
    "         }\n",
    "\n",
    "df2 = pd.DataFrame(dict2).T\n",
    "\n",
    "k = 10\n",
    "degree_freedom = k - 1         # d_f = k -1\n",
    "mean = df2.mean()\n",
    "variance = 0\n",
    "\n",
    "for i in range(len(df2.index)):\n",
    "    variance += pow((df2.iloc[i]['m1'] - df2.iloc[i]['m2']) - (mean[0]-mean[1]), 2)\n",
    "    \n",
    "variance = variance / k\n",
    "\n",
    "t = (mean[0] - mean[1]) / math.sqrt(variance / k)\n",
    "\n",
    "significance_level = 0.001\n",
    "\n",
    "t_distribution = 4.297\n",
    "\n",
    "print(\"With a significance level of {0} and degrees of freedom being {1}, the t-score is {2}.\".format(significance_level, degree_freedom, t_distribution))\n",
    "print(\"\\nOur t value, {0:4.3f}, is less than the t-distribution {1}, \\nmeaning that we must accept the null hypothesis.\".format(t, t_distribution))\n",
    "print(\"There is no statistical difference between the models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (b) Models are built and tested independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a significance level of 0.001 and degrees of freedom being 10, the t-score is 4.297.\n",
      "\n",
      "Our t value, 2.569, is less than the t-distribution 4.297, \n",
      "meaning that we must accept the null hypothesis.\n",
      "There is no statistical difference between the models.\n"
     ]
    }
   ],
   "source": [
    "degree_freedom = k\n",
    "\n",
    "variance = 0\n",
    "m1_var = 0\n",
    "m2_var = 0\n",
    "\n",
    "for i in range(len(df2.index)):\n",
    "    m1_var += pow((df2.iloc[i]['m1'] - mean[0]), 2)\n",
    "    m2_var += pow((df2.iloc[i]['m2'] - mean[1]), 2)\n",
    "    \n",
    "m1_var = m1_var / k\n",
    "m2_var = m2_var / k\n",
    "\n",
    "variance = (m1_var / k) + (m2_var / k)\n",
    "    \n",
    "t = (mean[0] - mean[1]) / math.sqrt(variance)\n",
    "\n",
    "significance_level = 0.001\n",
    "\n",
    "t_distribution = 4.297\n",
    "\n",
    "print(\"With a significance level of {0} and degrees of freedom being {1}, the t-score is {2}.\".format(significance_level, degree_freedom, t_distribution))\n",
    "print(\"\\nOur t value, {0:4.3f}, is less than the t-distribution {1}, \\nmeaning that we must accept the null hypothesis.\".format(t, t_distribution))\n",
    "print(\"There is no statistical difference between the models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Write a python jupyter notebook that performs a synchronized ten rounds 10-fold cross validation tests to obtain the classification accuracy scores for the Naive Bayesian and the AdaBoost classifiers learned from the dataset given in hwk07.csv, in which column H is the class label.  Specificially, in each round, the same training set should be used to train the classifiers, and the same testing set should be used to measure the classification accuracy scores.  Your program should use function from the scikit-learn to create random folds, to learn classifiers, to test the classifiers and to calculate classification accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes and AdaBoost Classifiers\n",
      "\n",
      "Fold     Naive Bayes       AdaBoost\n",
      "-----------------------------------\n",
      "  0         0.96             0.90\n",
      "  1         0.90             0.92\n",
      "  2         0.94             0.46\n",
      "  3         0.96             0.84\n",
      "  4         0.92             0.78\n",
      "  5         0.94             0.88\n",
      "  6         0.88             0.84\n",
      "  7         0.90             0.84\n",
      "  8         0.90             0.92\n",
      "  9         0.94             0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "x_cols = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "y_cols = ['H']\n",
    "\n",
    "df3 = pd.read_csv(\"hwk07.csv\")\n",
    "\n",
    "df3 = df3.apply(pd.to_numeric)\n",
    "\n",
    "X = df3[x_cols]\n",
    "\n",
    "y = df3[y_cols]\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "nb_list = []\n",
    "ada_list = []\n",
    "\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model_nb = GaussianNB()\n",
    "    \n",
    "    model_nb.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    nb_y_pred = model_nb.predict(X_test)\n",
    "    \n",
    "    nb_list.append(metrics.accuracy_score(y_test, nb_y_pred))\n",
    "    \n",
    "    model_ada = AdaBoostClassifier(random_state=0)\n",
    "    \n",
    "    model_ada.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    ada_y_pred = model_ada.predict(X_test)\n",
    "    \n",
    "    ada_list.append(metrics.accuracy_score(y_test, ada_y_pred))\n",
    "    \n",
    "print(\"Accuracy of Naive Bayes and AdaBoost Classifiers\\n\")\n",
    "\n",
    "print(\"Fold     Naive Bayes       AdaBoost\")\n",
    "print(\"-----------------------------------\")\n",
    "for i in range(len(nb_list)):\n",
    "    print(\"  {2}         {0:4.2f}             {1:4.2f}\".format(nb_list[i], ada_list[i], i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
